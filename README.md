# ğŸ›ï¸ Kallipolis Simulator: Investigating Classism in Platoâ€™s Ideal City Using LLM Agents

**Author:** Akshay Ravi  
**Date:** November 2025  
**Course:** DATA 512 â€“ Human-Centered Data Science, University of Washington  
**Status:** In Progress

---

## ğŸ§© Overview

This project explores whether **social class bias** can emerge in a simulated version of *Platoâ€™s Kallipolis* â€” the ideal city described in *The Republic* â€” when its citizens are represented by **large language model (LLM)** agents.

Each agent in the simulation plays a role from Platoâ€™s hierarchy â€” *Philosopher-Ruler, Guardians (Warriors), and Producers (Farmers, Builders, Merchants, Artists, etc.)* â€” and interacts rationally and virtuously to solve crises.  

The study asks:  
> *Do virtuous, role-defined AI agents display classism or favoritism over time, even when instructed to act rationally and benevolently?*

By analyzing the **language and decisions** of these agents, this project aims to understand whether social inequality can emerge inside AI-driven societies that imitate human civilizations.

---

## ğŸº Problem Statement

Platoâ€™s *Republic* envisions Kallipolis â€” a perfectly just city ruled by philosopher-kings, defended by warriors, and sustained by producers. Justice, he says, exists when everyone fulfills only the task suited to their â€œnature.â€

However, in history, hierarchical systems often collapse into **oppression and inequality**.  
This project investigates whether a similar phenomenon â€” *classism* â€” arises in a **non-human**, AI-based simulation of Kallipolis.

Even though each agent is designed to be rational and virtuous, the underlying LLMs may exhibit **linguistic traces of bias** (favoritism, deference, or dominance) reflecting human social hierarchies embedded in their training data.

From a human-centered data science perspective, the study aims to uncover how inequality can emerge (or fail to emerge) within synthetic societies.

---

## ğŸ§  Simulation Overview

### Framework & Implementation
- **Language Model:** [Ollama](https://ollama.ai/) local models (e.g., `llama3.1:8b-instruct-q8_0`)  
- **Agent Framework:** [AutoGen 0.7.5](https://github.com/microsoft/autogen)  
- **Core File:** `main.py`  
- **Logging:** Full JSONL transcript (`kallipolis_logs.jsonl`)  
- **Team Structure:**
  - **1 Ruler (Philosopher-King)**  
  - **4 Guardians (Warriors)**  
  - **20 Producers (Farmers, Builders, Merchants, Artists, Healers, Teachers)**  

Each simulated â€œyear,â€ the **Ruler** receives a crisis from the **God Agent**, consults the citizens, and issues a final directive.  
The entire multi-agent conversation is recorded as structured text for later analysis.

---

## ğŸ“Š Data

### Dataset
- **Source:** Generated entirely from the simulation (no human data).  
- **Format:** JSONL logs with fields:
  ```json
  {
    "timestamp": "2025-11-07T14:32:00",
    "speaker": "Warrior",
    "phase": "response",
    "message": "We must secure the granaries before the storm."
  }
